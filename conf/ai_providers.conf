//===== rAthena AI Providers Configuration ================================
//
// This file contains configuration settings for AI providers.
//
// Available providers:
// - azure_openai: Microsoft Azure OpenAI Service
// - openai: OpenAI API
// - deepseek: DeepSeek AI API
// - local: Local fallback provider
//
//=========================================================================

// Global AI Provider Settings
ai_enabled: true                     // Enable or disable AI functionality globally
ai_log_level: 3                      // Log level (0=none, 1=error, 2=warning, 3=info, 4=debug, 5=trace)
ai_cache_enabled: true               // Enable caching of AI responses to reduce API calls
ai_cache_ttl: 86400                  // Cache time-to-live in seconds (default: 1 day)
ai_primary_provider: "azure_openai"  // Primary AI provider to use
ai_fallback_provider: "local"        // Fallback AI provider if primary fails

//===== Azure OpenAI Configuration =======================================
azure_openai: {
    enabled: true                    // Enable Azure OpenAI integration
    api_key: "your_api_key_here"     // Your Azure OpenAI API key
    endpoint: "https://your-resource.openai.azure.com/"  // Azure OpenAI endpoint URL
    api_version: "2023-05-15"        // API version
    deployment_id: "your_deployment_id"  // Deployment ID for your model
    model: "gpt-4o"                  // Model name
    temperature: 0.7                 // Temperature for response generation (0.0-1.0)
    max_tokens: 1000                 // Maximum tokens per response
    top_p: 1.0                       // Top P sampling parameter
    frequency_penalty: 0.0           // Frequency penalty parameter
    presence_penalty: 0.0            // Presence penalty parameter
    timeout: 30                      // Request timeout in seconds
    retry_count: 3                   // Number of retries on failure
}

//===== OpenAI Configuration ============================================
openai: {
    enabled: true                    // Enable OpenAI integration
    api_key: "your_api_key_here"     // Your OpenAI API key
    organization_id: ""              // Organization ID (optional)
    model: "gpt-4o"                  // Model name
    temperature: 0.7                 // Temperature for response generation (0.0-1.0)
    max_tokens: 1000                 // Maximum tokens per response
    top_p: 1.0                       // Top P sampling parameter
    frequency_penalty: 0.0           // Frequency penalty parameter
    presence_penalty: 0.0            // Presence penalty parameter
    timeout: 30                      // Request timeout in seconds
    retry_count: 3                   // Number of retries on failure
}

//===== DeepSeek Configuration ==========================================
deepseek: {
    enabled: true                    // Enable DeepSeek integration
    api_key: "your_api_key_here"     // Your DeepSeek API key
    model: "deepseek-v3"             // Model name
    temperature: 0.7                 // Temperature for response generation (0.0-1.0)
    max_tokens: 1000                 // Maximum tokens per response
    top_p: 1.0                       // Top P sampling parameter
    frequency_penalty: 0.0           // Frequency penalty parameter
    presence_penalty: 0.0            // Presence penalty parameter
    timeout: 30                      // Request timeout in seconds
    retry_count: 3                   // Number of retries on failure
}

//===== Local Provider Configuration ===================================
local: {
    enabled: true                    // Enable local provider
    model_path: "./models/llama3"    // Path to local model files
    model_type: "llama"              // Type of local model
    context_size: 4096               // Context size for local model
    temperature: 0.7                 // Temperature for response generation (0.0-1.0)
    threads: 4                       // Number of threads for local model
    timeout: 60                      // Request timeout in seconds
}

//===== Cost Management Configuration ==================================
cost_management: {
    enabled: true                    // Enable cost management
    daily_budget: 10.0               // Daily budget in USD
    monthly_budget: 200.0            // Monthly budget in USD
    alert_threshold: 0.8             // Alert threshold (0.0-1.0)
    rate_limit_enabled: true         // Enable rate limiting
    rate_limit_requests: 100         // Maximum requests per minute
    priority_users: []               // List of user IDs with priority access
}

//===== Security Configuration =========================================
security: {
    encrypt_api_keys: true           // Encrypt API keys in memory
    input_sanitization: true         // Sanitize input before sending to AI
    output_filtering: true           // Filter output for inappropriate content
    abuse_detection: true            // Enable abuse detection
    max_request_size: 4096           // Maximum request size in bytes
    max_response_size: 16384         // Maximum response size in bytes
}